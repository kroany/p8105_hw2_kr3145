---
title: "p8105_hw2_kr3145"
author: "Kallan Roan"
date: "2025-09-23"
output: github_document
---

Load libraries
```{r}
library(tidyverse)
library(readxl)
```

# Problem 1

Read and clean pols-month.csv

```{r}
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(
    mon, into = c("year", "month", "day"), sep = "-", convert = TRUE
    ) |>
  mutate(
    month = month.name[month]
  ) |> 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president",
    values_to = "president_values",
    names_prefix = "prez_" 
  ) |> 
  filter(president_values == 1) |> 
  select(-day, -president_values) 
```
Read and clean snp.csv

```{r}
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(
    date, into = c("month", "day", "year"), sep = "/", convert = TRUE
  ) |> 
  mutate(
    year = ifelse(year <= 15, year + 2000, year + 1900)
  ) |> 
  select(year, month, close, -day) |> 
  arrange(year, month) |> 
  mutate(
    month = month.name[month]
  )
```
Read and clean unemployment.csv

```{r}
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) |> 
  mutate(
    month = month.name[match(toupper(month), toupper(month.abb))]
  )

```

Merge pols_month_df, snp_df, and unemployment_df

```{r}
# join datasets
pols_snp_unempl_df =
  left_join(pols_month_df, snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month")) 
```

PARAGRAPH ABOUT DESCRIPTION HERE
Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

pols_month_df from pols-month.csv contains 

snp_df from snp.csv contains 

unemployment_df from unemployment.csv contains the ...

- check snp.csv code


# Problem 2

Read and clean Mr. Trash Wheel dataset

```{r}
mr_trash_wheel_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N655") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.integer(year),
    trash_wheel = "mr"
  )
```
- 651 obs

Read and clean Professor Trash Wheel dataset

```{r}
prof_trash_wheel_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    trash_wheel = "prof"
  )
```
- 119 obs

Read and clean Gwynnda Trash Wheel dataset

```{r}
gwynnda_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    trash_wheel = "gwynnda"
  )
```
- 263 obs, 262 individual dumpsters

Bind mr_trash_wheel_df, prof_trash_wheel_df, and gwynnda_df
Create tidy dataset

```{r}
all_trash_wheel_df =
  bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynnda_df) |> 
  janitor::clean_names()
```

- pivot longer --> type of litter, and number????
- home powered?

The resulting dataset has `r nrow(all_trash_wheel_df)` observations. Some key 
variables include `weight_tons`, representing the weight of trash in tons, and  `volume_cubic_yards`, representing volume of trash in cubic yards. There are also other variables representing litter types, including `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, `plastic_bags`, and `wrappers`. `home_powered` represents the number of homes the amount of trash for the dumpster is able to power.  

The total weight of trash collected by Professor Trash Wheel is `r sum(pull(filter(all_trash_wheel_df, trash_wheel == "prof"), weight_tons), na.rm = TRUE)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r as.integer(sum(pull(filter(all_trash_wheel_df, trash_wheel == "gwynnda", month == "June", year == 2022), cigarette_butts), na.rm = TRUE))`.

# Problem 3

Read and clean Zip Codes.csv
```{r}
zip_code_df =
  read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  arrange(county, zip_code) |> 
  select(-state_fips, -file_date) 

```
- arrange by county and zip code
- remove state fips and file date
- rearrange to have variables start with county and zip code

Read and clean Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv

```{r}
zip_zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    col = x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to = "zori",
    names_prefix = "x"
  ) |> 
  separate(
    date, into = c("year", "month", "day"), sep = "_", convert = TRUE
  ) |> 
  rename(zip_code = region_name, county = county_name) |> 
  select(county, zip_code, everything(), -(region_type:metro), -day) |> 
  mutate(county = str_trim(str_remove(county, "County"))) |> 
  arrange(county, zip_code) 

  
```
- remove region_type, state_name, city, 
- rename region_name to zip_code
- pivot longer
- clean up date variable
- fix county_name to remove County
- rearrange to have variables start with county and zip code
- ???remove NA values???

Merge zip_zori_df and zip_code_df

```{r}

```

For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. 
Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021. 


