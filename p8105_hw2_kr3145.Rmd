---
title: "p8105_hw2_kr3145"
author: "Kallan Roan"
date: "2025-09-23"
output: github_document
---

Load libraries
```{r}
library(tidyverse)
library(readxl)
```

# Problem 1

Read and clean pols-month.csv

```{r}
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(
    mon, into = c("year", "month", "day"), sep = "-", convert = TRUE
    ) |>
  mutate(
    month = month.name[month]
  ) |> 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president",
    values_to = "president_values",
    names_prefix = "prez_" 
  ) |> 
  filter(president_values == 1) |> 
  select(-day, -president_values) 
```
Read and clean snp.csv

```{r}
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(
    date, into = c("month", "day", "year"), sep = "/", convert = TRUE
  ) |> 
  mutate(
    year = ifelse(year <= 15, year + 2000, year + 1900)
  ) |> 
  select(year, month, close, -day) |> 
  arrange(year, month) |> 
  mutate(
    month = month.name[month]
  )
```

Read and clean unemployment.csv

```{r}
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) |> 
  mutate(
    month = month.name[match(toupper(month), toupper(month.abb))]
  )

```

Merge pols_month_df, snp_df, and unemployment_df

```{r}
# join datasets
pols_snp_unempl_df =
  left_join(pols_month_df, snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

- check snp.csv code

`pols_month_df` from pols-month.csv contains the number of national politicians who are democratic or republican at any given time. `snp_df` from snp.csv contains contains information about the Standard & Poor's stock market index (S&P), which is used as a representative measure of stock market as a whole. `unemployment_df` from unemployment.csv contains monthly percentage of unemployment for the associated year. After tidying and merging the above datasets, the resulting dataset, `pols_snp_unempl_df` contains `r nrow(pols_snp_unempl_df)` observations and `r ncol(pols_snp_unempl_df)` variables. The dataset represents the years ranging from `r min(pull(pols_snp_unempl_df, year))` to `r max(pull(pols_snp_unempl_df, year))`. 

`gov_gop`, `sen_gop`, and `rep_gop` represents the number of governors, senators, and representatives in the republican party on the associated date. `gov_dem`, `sen_dem`, and `rep_dem` represents the number of governors, senators, and representatives in the democratic party during the associated date. `president` indicates whether the president was republican or democratic during the associated date. `close` represents the closing values of the S&P stock index on the associated date. `percent_unemployed` represents the percentage of unemployment during the associated date. 

# Problem 2

Read and clean Mr. Trash Wheel dataset

```{r}
mr_trash_wheel_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N655") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.integer(year),
    trash_wheel = "mr"
  )
```
- 651 obs

Read and clean Professor Trash Wheel dataset

```{r}
prof_trash_wheel_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    trash_wheel = "prof"
  )
```
- 119 obs

Read and clean Gwynnda Trash Wheel dataset

```{r}
gwynnda_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    trash_wheel = "gwynnda"
  )
```
- 263 obs, 262 individual dumpsters

Bind mr_trash_wheel_df, prof_trash_wheel_df, and gwynnda_df
Create tidy dataset

```{r}
all_trash_wheel_df =
  bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynnda_df) |> 
  janitor::clean_names()
```

- pivot longer --> type of litter, and number????
- home powered?

SHOW YEAR RANGE???

The resulting dataset has `r nrow(all_trash_wheel_df)` observations. Some key 
variables include `weight_tons`, representing the weight of trash in tons, and  `volume_cubic_yards`, representing volume of trash in cubic yards. There are also other variables representing litter types, including `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, `plastic_bags`, and `wrappers`. `home_powered` represents the number of homes the amount of trash for the dumpster is able to power.  

The total weight of trash collected by Professor Trash Wheel is `r sum(pull(filter(all_trash_wheel_df, trash_wheel == "prof"), weight_tons), na.rm = TRUE)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r as.integer(sum(pull(filter(all_trash_wheel_df, trash_wheel == "gwynnda", month == "June", year == 2022), cigarette_butts), na.rm = TRUE))`.

# Problem 3

Read and clean Zip Codes.csv
```{r}
zip_code_df =
  read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  arrange(county, zip_code) |> 
  select(-(state_fips:county_fips), -file_date) 

```
- arrange by county and zip code
- remove state fips and file date
- rearrange to have variables start with county and zip code

Read and clean Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv

```{r}
zip_zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    col = x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to = "zori",
    names_prefix = "x"
  ) |> 
  separate(
    date, into = c("year", "month", "day"), sep = "_", convert = TRUE
  ) |> 
  rename(zip_code = region_name, county = county_name) |> 
  select(county, zip_code, everything(), -(region_type:metro), -region_id, -size_rank, -day) |> 
  mutate(county = str_trim(str_remove(county, "County"))) |> 
  arrange(county, zip_code) 

  
```
- remove region_type, state_name, city, 
- rename region_name to zip_code
- pivot longer
- clean up date variable
- fix county_name to remove County
- rearrange to have variables start with county and zip code
- ???remove NA values???

Merge zip_zori_df and zip_code_df

```{r}
combined_zip_zori_df =
  left_join(zip_code_df, zip_zori_df, by = c("county", "zip_code")) |> 
  janitor::clean_names()
```

PARAPGRAPH DESCRIPTION

The dataset has `r nrow(combined_zip_zori_df)` observations. There are `r length(unique(pull(combined_zip_zori_df, zip_code)))` unique zip codes and `r length(unique(pull(combined_zip_zori_df, neighborhood)))` unique neighborhoods in the dataset.

Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

`r as.integer(unique(pull(filter(combined_zip_zori_df, is.na(year)), zip_code)))` are  zip codes that appear in the ZIP code dataset but not in the Zillow Rental Price dataset. 

These zip codes may be excluded from the Zillow dataset because 
- those areas don't have much rental housing, so not enough data to produce a reliable ZORI score?
- some of these zip codes are associated with a unique-non-geographic zip code, more specifically a single large address or building complex. It is not associated with a traditioanl neighborhood or borough.  some may be associated with po box, or also government offices. (JFK airport) 
- some zip codes cover multiple geographic areas/boroughs/some are part of new york state, not NYC
- some zip codes cover universities, hostpials, military facilities??

For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. 

Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.

```{r}
combined_zip_zori_df |> 
  arrange(zip_code) |> 
  filter(month == 1, 
         year %in% c(2020, 2021)) |> #only keep zori scores from January 2020 and 2021
  select(-month) |> #remove month column
  pivot_wider(
    names_from = year,
    values_from = zori,
    #names_prefix = "year_"
  ) |> 
  drop_na(`2020`, `2021`) |> # drop rows that have NA values in either 2020 or 2021
  mutate(
    difference = `2020` - `2021` # more postiive number, larger drop in price
  ) |> 
  arrange(desc(difference)) |> 
  head(10) |> 
  knitr::kable()
```




